{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HACK-IIITV-Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUBO2x6FvPjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from xgboost import XGBRegressor\n",
        "import xlsxwriter\n",
        "import chardet\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numpy import array\n",
        "from numpy import argmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YBanrXtvc-n",
        "colab_type": "code",
        "outputId": "f6e718c9-c1d2-4c16-fd64-39e1e024b4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install xlsxwriter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/50/780122e4790328c195475d6e49a07fb69593508355dfee98bfb22686d9e8/XlsxWriter-1.2.1-py2.py3-none-any.whl (140kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 81kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 92kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-jlvR4G8DSM",
        "colab_type": "code",
        "outputId": "97eca9cd-1c05-47d4-cc13-e8f7d7b6b069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "input_data = pd.read_excel('X_train.xlsx')\n",
        "input_data = input_data.iloc[:, :-1].values\n",
        "print(input_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00000e+00  2.10000e+01  1.20000e+02  7.50000e+00  2.86000e-01\n",
            "   8.10000e-01  3.89407e+02  2.34600e+01  7.78400e+02  1.35000e+00\n",
            "   2.75000e+00  1.47200e+01  1.67700e+01  8.28000e+00  8.00000e+00\n",
            "  -2.18400e+02 -1.17800e+02 -5.82000e+01 -1.04000e+02 -1.16900e+02\n",
            "  -5.30000e+01  6.92000e+01  1.85000e+01 -9.85000e+01 -1.18100e+02\n",
            "  -1.23000e+02]\n",
            " [ 1.00000e+00  1.85000e+01  1.35000e+02  7.20000e+00  2.68000e-01\n",
            "   7.50000e-01  3.60685e+02  9.90000e+00  5.54064e+02  6.00000e-01\n",
            "   3.11000e+00  1.53200e+01  1.32700e+01  1.65600e+01  8.00000e+00\n",
            "  -6.84000e+01 -4.28000e+01  1.68000e+01 -2.90000e+01 -4.19000e+01\n",
            "   2.20000e+01  1.44200e+02  9.35000e+01 -2.35000e+01 -4.31000e+01\n",
            "  -4.80000e+01]\n",
            " [ 2.00000e+00  2.00000e+01  1.60000e+02  7.40000e+00  1.99000e-01\n",
            "   8.55000e-01  4.10949e+02  5.54000e+00  1.65536e+02  6.00000e-01\n",
            "   5.00000e+00  2.44900e+01  2.63900e+01  6.21000e+00  8.00000e+00\n",
            "  -4.34000e+01 -3.03000e+01  2.93000e+01 -1.65000e+01 -2.94000e+01\n",
            "   3.45000e+01  1.56700e+02  1.06000e+02 -1.10000e+01 -3.06000e+01\n",
            "  -3.55000e+01]\n",
            " [ 3.00000e+00  2.75000e+01  1.20000e+02  6.90000e+00  2.20000e-01\n",
            "   7.50000e-01  3.60685e+02  2.69300e+01  3.23008e+02  1.40000e-01\n",
            "   1.66000e+00  1.03100e+01  9.41000e+00  1.44900e+01  8.00000e+00\n",
            "  -2.08400e+02 -1.12800e+02 -5.32000e+01 -9.90000e+01 -1.11900e+02\n",
            "  -4.80000e+01  7.42000e+01  2.35000e+01 -9.35000e+01 -1.13100e+02\n",
            "  -1.18000e+02]\n",
            " [ 4.00000e+00  2.10000e+01  1.20000e+02  7.50000e+00  2.86000e-01\n",
            "   8.10000e-01  3.89407e+02  2.34600e+01  7.78400e+02  1.35000e+00\n",
            "   2.75000e+00  1.47200e+01  1.67700e+01  8.28000e+00  8.00000e+00\n",
            "  -2.37200e+02 -1.23200e+02 -9.78000e+01 -8.63000e+01 -8.55000e+01\n",
            "  -2.90000e+00  1.06500e+02  1.62000e+02 -2.33000e+01 -1.14600e+02\n",
            "  -1.25000e+02]\n",
            " [ 5.00000e+00  2.50000e+01  1.20000e+02  7.10000e+00  1.78000e-01\n",
            "   3.80000e-01  1.83566e+02  3.09000e+01  2.91200e+02  1.80000e-01\n",
            "   1.58000e+00  1.44900e+01  1.40500e+01  1.65600e+01  8.00000e+00\n",
            "  -3.37200e+02 -1.73200e+02 -1.47800e+02 -1.36300e+02 -1.35500e+02\n",
            "  -5.29000e+01  5.65000e+01  1.12000e+02 -7.33000e+01 -1.64600e+02\n",
            "  -1.75000e+02]\n",
            " [ 6.00000e+00  3.00000e+01  9.50000e+01  7.60000e+00  1.74000e-01\n",
            "   3.60000e-01  1.73992e+02  4.95000e+01  3.02960e+02  3.60000e-01\n",
            "   1.59000e+00  1.05800e+01  8.13000e+00  1.17300e+01  8.00000e+00\n",
            "  -3.87200e+02 -1.98200e+02 -1.72800e+02 -1.61300e+02 -1.60500e+02\n",
            "  -7.79000e+01  3.15000e+01  8.70000e+01 -9.83000e+01 -1.89600e+02\n",
            "  -2.00000e+02]\n",
            " [ 7.00000e+00  2.50000e+01  1.30000e+02  7.90000e+00  1.58000e-01\n",
            "   3.90000e-01  1.88353e+02  1.11000e+01  3.32304e+02  9.00000e-02\n",
            "   2.71000e+00  7.51000e+00  9.43000e+00  1.17300e+01  8.00000e+00\n",
            "  -3.87200e+02 -1.98200e+02 -1.72800e+02 -1.61300e+02 -1.60500e+02\n",
            "  -7.79000e+01  3.15000e+01  8.70000e+01 -9.83000e+01 -1.89600e+02\n",
            "  -2.00000e+02]\n",
            " [ 8.00000e+00  2.10000e+01  1.20000e+02  7.50000e+00  2.86000e-01\n",
            "   8.10000e-01  3.89407e+02  2.34600e+01  7.78400e+02  1.35000e+00\n",
            "   2.75000e+00  1.47200e+01  1.67700e+01  8.28000e+00  6.00000e+00\n",
            "  -2.32300e+02 -9.37000e+01 -5.65000e+01 -9.52000e+01 -1.08300e+02\n",
            "  -7.67000e+01  5.20000e+00 -3.64000e+01 -5.58000e+01 -1.16000e+02\n",
            "  -1.24200e+02]\n",
            " [ 9.00000e+00  1.85000e+01  1.35000e+02  7.20000e+00  2.68000e-01\n",
            "   7.50000e-01  3.60685e+02  9.90000e+00  5.54064e+02  6.00000e-01\n",
            "   3.11000e+00  1.53200e+01  1.32700e+01  1.65600e+01  6.00000e+00\n",
            "  -8.23000e+01 -1.87000e+01  1.85000e+01 -2.02000e+01 -3.33000e+01\n",
            "  -1.70000e+00  8.02000e+01  3.86000e+01  1.92000e+01 -4.10000e+01\n",
            "  -4.92000e+01]\n",
            " [ 1.00000e+01  2.35000e+01  1.40000e+02  7.10000e+00  2.26000e-01\n",
            "   6.60000e-01  3.17602e+02  1.46500e+01  3.34096e+02  7.10000e-01\n",
            "   2.57000e+00  1.66200e+01  1.91800e+01  1.72500e+01  6.00000e+00\n",
            "  -6.23000e+01 -8.70000e+00  2.85000e+01 -1.02000e+01 -2.33000e+01\n",
            "   8.30000e+00  9.02000e+01  4.86000e+01  2.92000e+01 -3.10000e+01\n",
            "  -3.92000e+01]\n",
            " [ 1.10000e+01  2.75000e+01  1.20000e+02  6.90000e+00  2.20000e-01\n",
            "   7.50000e-01  3.60685e+02  2.69300e+01  3.23008e+02  1.40000e-01\n",
            "   1.66000e+00  1.03100e+01  9.41000e+00  1.44900e+01  6.00000e+00\n",
            "  -2.22300e+02 -8.87000e+01 -5.15000e+01 -9.02000e+01 -1.03300e+02\n",
            "  -7.17000e+01  1.02000e+01 -3.14000e+01 -5.08000e+01 -1.11000e+02\n",
            "  -1.19200e+02]\n",
            " [ 1.20000e+01  1.85000e+01  1.35000e+02  7.20000e+00  2.68000e-01\n",
            "   7.50000e-01  3.60685e+02  9.90000e+00  5.54064e+02  6.00000e-01\n",
            "   3.11000e+00  1.53200e+01  1.32700e+01  1.65600e+01  5.00000e+00\n",
            "  -9.86000e+01 -4.92000e+01 -8.80000e+00 -4.04000e+01 -2.56000e+01\n",
            "   1.27000e+02  6.17000e+01  1.72000e+01  9.66000e+01 -1.70000e+00\n",
            "  -3.38000e+01]\n",
            " [ 1.30000e+01  2.10000e+01  9.50000e+01  7.50000e+00  1.38000e-01\n",
            "   3.30000e-01  1.59631e+02  6.73000e+00  2.14928e+02  2.80000e-01\n",
            "   1.76000e+00  1.27000e+01  1.08500e+01  1.31100e+01  7.00000e+00\n",
            "  -1.78600e+02 -8.92000e+01 -4.88000e+01 -8.04000e+01 -6.56000e+01\n",
            "   8.70000e+01  2.17000e+01 -2.28000e+01  5.66000e+01 -4.17000e+01\n",
            "  -7.38000e+01]\n",
            " [ 1.40000e+01  2.35000e+01  8.00000e+01  7.60000e+00  1.52000e-01\n",
            "   4.80000e-01  2.31436e+02  9.50000e+00  4.07344e+02  3.20000e-01\n",
            "   1.41000e+00  1.79100e+01  8.98000e+00  2.00100e+01  5.00000e+00\n",
            "  -8.36000e+01 -4.17000e+01 -1.30000e+00 -3.29000e+01 -1.81000e+01\n",
            "   1.34500e+02  6.92000e+01  2.47000e+01  1.04100e+02  5.80000e+00\n",
            "  -2.63000e+01]\n",
            " [ 1.50000e+01  2.00000e+01  1.60000e+02  7.40000e+00  1.99000e-01\n",
            "   8.55000e-01  4.10949e+02  5.54000e+00  1.65536e+02  6.00000e-01\n",
            "   5.00000e+00  2.44900e+01  2.63900e+01  6.21000e+00  5.00000e+00\n",
            "  -7.36000e+01 -3.67000e+01  3.70000e+00 -2.79000e+01 -1.31000e+01\n",
            "   1.39500e+02  7.42000e+01  2.97000e+01  1.09100e+02  1.08000e+01\n",
            "  -2.13000e+01]\n",
            " [ 1.60000e+01  2.25000e+01  1.87000e+02  8.10000e+00  2.10000e-01\n",
            "   4.20000e-01  2.02714e+02  2.89100e+01  4.13280e+02  2.20000e-01\n",
            "   9.00000e-01  4.94000e+00  4.40000e+00  2.13900e+01  5.00000e+00\n",
            "  -1.68600e+02 -8.42000e+01 -4.38000e+01 -7.54000e+01 -6.06000e+01\n",
            "   9.20000e+01  2.67000e+01 -1.78000e+01  6.16000e+01 -3.67000e+01\n",
            "  -6.88000e+01]\n",
            " [ 1.70000e+01  3.00000e+01  9.50000e+01  7.60000e+00  1.74000e-01\n",
            "   3.60000e-01  1.73992e+02  4.95000e+01  3.02960e+02  3.60000e-01\n",
            "   1.59000e+00  1.05800e+01  8.13000e+00  1.17300e+01  7.00000e+00\n",
            "  -3.98600e+02 -1.99200e+02 -1.58800e+02 -1.90400e+02 -1.75600e+02\n",
            "  -2.30000e+01 -8.83000e+01 -1.32800e+02 -5.34000e+01 -1.51700e+02\n",
            "  -1.83800e+02]\n",
            " [ 1.80000e+01  2.10000e+01  9.50000e+01  7.50000e+00  1.38000e-01\n",
            "   3.30000e-01  1.59631e+02  6.73000e+00  2.14928e+02  2.80000e-01\n",
            "   1.76000e+00  1.27000e+01  1.08500e+01  1.31100e+01  7.00000e+00\n",
            "  -1.78300e+02 -8.98000e+01 -6.56000e+01 -9.50000e+00  3.53000e+01\n",
            "   1.28700e+02  2.20000e+01  4.66000e+01  7.45000e+01  1.61000e+01\n",
            "   4.81000e+01]\n",
            " [ 1.90000e+01  2.75000e+01  1.25000e+02  7.30000e+00  1.70000e-01\n",
            "   4.95000e-01  2.38617e+02  1.62300e+01  1.35073e+02  6.00000e-01\n",
            "   1.40000e+00  1.06400e+01  1.09500e+01  1.51800e+01  3.00000e+00\n",
            "  -9.83000e+01 -4.98000e+01 -2.56000e+01  3.05000e+01  7.53000e+01\n",
            "   1.68700e+02  6.20000e+01  8.66000e+01  1.14500e+02  5.61000e+01\n",
            "   8.81000e+01]\n",
            " [ 2.00000e+01  2.25000e+01  1.87000e+02  8.10000e+00  2.10000e-01\n",
            "   4.20000e-01  2.02714e+02  2.89100e+01  4.13280e+02  2.20000e-01\n",
            "   9.00000e-01  4.94000e+00  4.40000e+00  2.13900e+01  3.00000e+00\n",
            "  -1.68300e+02 -8.48000e+01 -6.06000e+01 -4.50000e+00  4.03000e+01\n",
            "   1.33700e+02  2.70000e+01  5.16000e+01  7.95000e+01  2.11000e+01\n",
            "   5.31000e+01]\n",
            " [ 2.10000e+01  2.70000e+01  1.10000e+02  7.30000e+00  1.66000e-01\n",
            "   4.00000e-01  1.93140e+02  2.44000e+01  2.40128e+02  3.00000e-01\n",
            "   2.19000e+00  3.88000e+00  4.74000e+00  1.24200e+01  3.00000e+00\n",
            "  -3.48300e+02 -1.74800e+02 -1.50600e+02 -9.45000e+01 -4.97000e+01\n",
            "   4.37000e+01 -6.30000e+01 -3.84000e+01 -1.05000e+01 -6.89000e+01\n",
            "  -3.69000e+01]\n",
            " [ 2.20000e+01  2.70000e+01  1.10000e+02  8.00000e+00  1.75000e-01\n",
            "   4.35000e-01  2.09894e+02  4.75000e+00  1.38544e+02  2.80000e-01\n",
            "   1.25000e+00  4.40000e+00  4.12000e+00  8.97000e+00  3.00000e+00\n",
            "  -3.48300e+02 -1.74800e+02 -1.50600e+02 -9.45000e+01 -4.97000e+01\n",
            "   4.37000e+01 -6.30000e+01 -3.84000e+01 -1.05000e+01 -6.89000e+01\n",
            "  -3.69000e+01]\n",
            " [ 2.30000e+01  2.75000e+01  1.25000e+02  7.30000e+00  1.70000e-01\n",
            "   4.95000e-01  2.38617e+02  1.62300e+01  1.35073e+02  6.00000e-01\n",
            "   1.40000e+00  1.06400e+01  1.09500e+01  1.51800e+01  4.00000e+00\n",
            "  -9.69000e+01 -4.42000e+01  1.00000e-01  1.64100e+02  1.51800e+02\n",
            "   5.13600e+02  3.56000e+02  2.02200e+02  2.42900e+02  2.58100e+02\n",
            "   1.73600e+02]\n",
            " [ 2.40000e+01  2.70000e+01  1.10000e+02  7.30000e+00  1.66000e-01\n",
            "   4.00000e-01  1.93140e+02  2.44000e+01  2.40128e+02  3.00000e-01\n",
            "   2.19000e+00  3.88000e+00  4.74000e+00  1.24200e+01  4.00000e+00\n",
            "  -3.46900e+02 -1.69200e+02 -1.24900e+02  3.91000e+01  2.68000e+01\n",
            "   3.88600e+02  2.31000e+02  7.72000e+01  1.17900e+02  1.33100e+02\n",
            "   4.86000e+01]\n",
            " [ 2.50000e+01  2.70000e+01  9.50000e+01  7.80000e+00  1.71000e-01\n",
            "   2.70000e-01  1.30909e+02  3.89000e+01  2.88736e+02  1.30000e-01\n",
            "   7.80000e-01  5.62000e+00  3.24000e+00  8.28000e+00  4.00000e+00\n",
            "  -3.96900e+02 -1.94200e+02 -1.49900e+02  1.41000e+01  1.80000e+00\n",
            "   3.63600e+02  2.06000e+02  5.22000e+01  9.29000e+01  1.08100e+02\n",
            "   2.36000e+01]\n",
            " [ 2.60000e+01  2.70000e+01  1.10000e+02  8.00000e+00  1.75000e-01\n",
            "   4.35000e-01  2.09894e+02  4.75000e+00  1.38544e+02  2.80000e-01\n",
            "   1.25000e+00  4.40000e+00  4.12000e+00  8.97000e+00  4.00000e+00\n",
            "  -3.46900e+02 -1.69200e+02 -1.24900e+02  3.91000e+01  2.68000e+01\n",
            "   3.88600e+02  2.31000e+02  7.72000e+01  1.17900e+02  1.33100e+02\n",
            "   4.86000e+01]\n",
            " [ 2.70000e+01  2.60000e+01  1.65000e+02  8.00000e+00  2.50000e-01\n",
            "   3.30000e-01  1.59631e+02  2.49400e+01  2.96240e+02  4.40000e-01\n",
            "   1.47000e+00  7.96000e+00  5.83000e+00  5.52000e+00  4.00000e+00\n",
            "  -4.96900e+02 -2.44200e+02 -1.99900e+02 -3.59000e+01 -4.82000e+01\n",
            "   3.13600e+02  1.56000e+02  2.20000e+00  4.29000e+01  5.81000e+01\n",
            "  -2.64000e+01]\n",
            " [ 2.80000e+01  2.35000e+01  1.40000e+02  7.10000e+00  2.26000e-01\n",
            "   6.60000e-01  3.17602e+02  1.46500e+01  3.34096e+02  7.10000e-01\n",
            "   2.57000e+00  1.66200e+01  1.91800e+01  1.72500e+01  2.00000e+00\n",
            "  -7.82000e+01 -4.00000e+01 -3.39000e+01 -3.45000e+01 -3.91000e+01\n",
            "   8.07000e+01  3.14700e+02 -2.60000e+00  5.34000e+01 -3.78000e+01\n",
            "  -3.97000e+01]\n",
            " [ 2.90000e+01  2.50000e+01  1.00000e+02  7.00000e+00  9.00000e-02\n",
            "   4.50000e-01  2.17075e+02  7.12000e+00  5.62240e+02  5.70000e-01\n",
            "   2.59000e+00  1.83800e+01  1.24400e+01  5.52000e+00  2.00000e+00\n",
            "  -1.25200e+02 -6.35000e+01 -5.74000e+01 -5.80000e+01 -6.26000e+01\n",
            "   5.72000e+01  2.91200e+02 -2.61000e+01  2.99000e+01 -6.13000e+01\n",
            "  -6.32000e+01]\n",
            " [ 3.00000e+01  2.25000e+01  1.87000e+02  8.10000e+00  2.10000e-01\n",
            "   4.20000e-01  2.02714e+02  2.89100e+01  4.13280e+02  2.20000e-01\n",
            "   9.00000e-01  4.94000e+00  4.40000e+00  2.13900e+01  2.00000e+00\n",
            "  -1.68200e+02 -8.50000e+01 -7.89000e+01 -7.95000e+01 -8.41000e+01\n",
            "   3.57000e+01  2.69700e+02 -4.76000e+01  8.40000e+00 -8.28000e+01\n",
            "  -8.47000e+01]\n",
            " [ 3.10000e+01  2.50000e+01  1.20000e+02  7.10000e+00  1.78000e-01\n",
            "   3.80000e-01  1.83566e+02  3.09000e+01  2.91200e+02  1.80000e-01\n",
            "   1.58000e+00  1.44900e+01  1.40500e+01  1.65600e+01  1.00000e+00\n",
            "  -3.36600e+02 -1.59500e+02 -1.37500e+02  7.59000e+01  1.57500e+02\n",
            "   3.83500e+02  1.25100e+02  4.15900e+02  1.04900e+02 -1.12400e+02\n",
            "  -1.61000e+02]\n",
            " [ 3.20000e+01  3.00000e+01  9.50000e+01  7.60000e+00  1.74000e-01\n",
            "   3.60000e-01  1.73992e+02  4.95000e+01  3.02960e+02  3.60000e-01\n",
            "   1.59000e+00  1.05800e+01  8.13000e+00  1.17300e+01  1.00000e+00\n",
            "  -3.86600e+02 -1.84500e+02 -1.62500e+02  5.09000e+01  1.32500e+02\n",
            "   3.58500e+02  1.00100e+02  3.90900e+02  7.99000e+01 -1.37400e+02\n",
            "  -1.86000e+02]\n",
            " [ 3.30000e+01  2.50000e+01  1.30000e+02  7.90000e+00  1.58000e-01\n",
            "   3.90000e-01  1.88353e+02  1.11000e+01  3.32304e+02  9.00000e-02\n",
            "   2.71000e+00  7.51000e+00  9.43000e+00  1.17300e+01  1.00000e+00\n",
            "  -3.86600e+02 -1.84500e+02 -1.62500e+02  5.09000e+01  1.32500e+02\n",
            "   3.58500e+02  1.00100e+02  3.90900e+02  7.99000e+01 -1.37400e+02\n",
            "  -1.86000e+02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv9YrsxFFTfe",
        "colab_type": "code",
        "outputId": "606fa500-9c7b-47f9-f918-2d70c455fe33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(output_data)\n",
        "print(output_data)\n",
        "\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Rice', 'Wheat', 'Lentil', 'Sugarcane', 'Rice', 'Tea', 'Jute', 'Turmeric', 'Rice', 'Wheat', 'Oilseeds', 'Sugarcane', 'Wheat', 'Maize', 'Pulses', 'Lentil', 'Cotton', 'Jute', 'Maize', 'Millets', 'Cotton', 'Cocoa', 'Coconut', 'Millets', 'Cocoa', 'Rubber', 'Coconut', 'Black Pepper', 'Oilseeds', 'Groundnut', 'Cotton', 'Tea', 'Jute', 'Turmeric']\n",
            "[11 16  6 13 11 14  5 15 11 16  9 13 16  7 10  6  3  5  7  8  3  1  2  8\n",
            "  1 12  2  0  9  4  3 14  5 15]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "['Rice']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp3WA3QjvhwX",
        "colab_type": "code",
        "outputId": "ea7d44fe-5d02-407c-bf2c-36f39e367378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "xgb_model = XGBRegressor(max_depth=8, \n",
        "                         n_estimators=500, \n",
        "                         min_child_weight=1000,  \n",
        "                         colsample_bytree=0.7, \n",
        "                         subsample=0.7, \n",
        "                         eta=0.3, \n",
        "                         seed=0)\n",
        "xgb_model.fit(input_data, \n",
        "              onehot_encoded , \n",
        "              eval_metric=\"rmse\", \n",
        "              eval_set=[(input_data, onehot_encoded )], \n",
        "              verbose=20, \n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[04:22:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:0.466264\n",
            "[20]\tvalidation_0-rmse:0.24338\n",
            "[40]\tvalidation_0-rmse:0.235789\n",
            "[60]\tvalidation_0-rmse:0.235355\n",
            "[80]\tvalidation_0-rmse:0.235307\n",
            "[100]\tvalidation_0-rmse:0.235339\n",
            "[120]\tvalidation_0-rmse:0.235296\n",
            "[140]\tvalidation_0-rmse:0.235324\n",
            "[160]\tvalidation_0-rmse:0.235321\n",
            "[180]\tvalidation_0-rmse:0.235319\n",
            "[200]\tvalidation_0-rmse:0.235385\n",
            "[220]\tvalidation_0-rmse:0.235296\n",
            "[240]\tvalidation_0-rmse:0.235294\n",
            "[260]\tvalidation_0-rmse:0.235294\n",
            "[280]\tvalidation_0-rmse:0.235321\n",
            "[300]\tvalidation_0-rmse:0.235347\n",
            "[320]\tvalidation_0-rmse:0.235302\n",
            "[340]\tvalidation_0-rmse:0.235645\n",
            "[360]\tvalidation_0-rmse:0.235468\n",
            "[380]\tvalidation_0-rmse:0.235642\n",
            "[400]\tvalidation_0-rmse:0.235297\n",
            "[420]\tvalidation_0-rmse:0.235296\n",
            "[440]\tvalidation_0-rmse:0.2353\n",
            "[460]\tvalidation_0-rmse:0.235296\n",
            "[480]\tvalidation_0-rmse:0.235379\n",
            "[499]\tvalidation_0-rmse:0.235393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=8, min_child_weight=1000, missing=None, n_estimators=500,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=None,\n",
              "             subsample=0.7, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8QFhDM-WEP_",
        "colab_type": "code",
        "outputId": "2b67e4ae-86f6-4a34-a70c-b114f7d088aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "rf_model = RandomForestRegressor(n_estimators=50, max_depth=7, random_state=0, n_jobs=-1)\n",
        "rf_model.fit(input_data,onehot_encoded)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
              "                      oob_score=False, random_state=0, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kne-kY_tX3Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "8bdc1a68-8d72-45b4-a1ef-4867c575de67"
      },
      "source": [
        "rf_train_pred = rf_model.predict([input_data[1]])  # or some 2D [[        ]] array\n",
        "pred_prob = np.squeeze(rf_train_pred)\n",
        "print(pred_prob)\n",
        "pred_prob = list(pred_prob)\n",
        "class_index = pred_prob.index(max(pred_prob))\n",
        "output_encoding = [0 for _ in range(onehot_encoded.shape[1]) ]\n",
        "output_encoding[class_index] = 1\n",
        "print(output_encoding)\n",
        "inverted = label_encoder.inverse_transform([argmax(output_encoding)])\n",
        "print(inverted)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.00768926 0.02114164 0.01510073 0.00911783 0.01507937 0.005\n",
            " 0.01123016 0.01150794 0.01292735 0.05025946 0.0190293  0.00730159\n",
            " 0.0180464  0.01507937 0.03623016 0.01480159 0.73045788]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "['Wheat']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPwVbp5X9rW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "741db38b-4241-41e7-b540-d51182c0ee54"
      },
      "source": [
        "rf_train_pred = rf_model.predict(input_data) \n",
        "print('Train rmse:', np.sqrt(mean_squared_error(onehot_encoded, rf_train_pred)))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train rmse: 0.1273710198239808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8pZeKSYGoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_scaler = MinMaxScaler()\n",
        "lr_scaler.fit(input_data)\n",
        "lr_train = lr_scaler.transform(input_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBBK7tJkb9vJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff0a7f73-fa51-4358-f782-a5598c10a2fc"
      },
      "source": [
        "lr_model = LinearRegression(n_jobs=-1)\n",
        "lr_model.fit(input_data, onehot_encoded)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=-1, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfwACESCcGtR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_train_pred = lr_model.predict(lr_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfG2RqZucKFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1ed96da-16f5-49e8-ac51-e748a78ee3e9"
      },
      "source": [
        "print('Train rmse:', np.sqrt(mean_squared_error(onehot_encoded, lr_train_pred)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train rmse: 122740.53603961515\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J35_AlRCcNew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}