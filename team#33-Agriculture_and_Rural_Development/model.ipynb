{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HACK-IIITV-Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUBO2x6FvPjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "from xgboost import XGBRegressor\n",
        "import xlsxwriter\n",
        "import chardet\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from numpy import array\n",
        "from numpy import argmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YBanrXtvc-n",
        "colab_type": "code",
        "outputId": "f6e718c9-c1d2-4c16-fd64-39e1e024b4a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "!pip install xlsxwriter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xlsxwriter\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/50/780122e4790328c195475d6e49a07fb69593508355dfee98bfb22686d9e8/XlsxWriter-1.2.1-py2.py3-none-any.whl (140kB)\n",
            "\r\u001b[K     |██▎                             | 10kB 19.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 20kB 4.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 40kB 4.1MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 61kB 5.8MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 81kB 6.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 92kB 7.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 102kB 6.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 112kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 122kB 6.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 133kB 6.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 143kB 6.8MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-jlvR4G8DSM",
        "colab_type": "code",
        "outputId": "97eca9cd-1c05-47d4-cc13-e8f7d7b6b069",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "input_data = pd.read_excel('X_train.xlsx')\n",
        "input_data = input_data.iloc[:, :-1].values\n",
        "print(input_data)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00000e+00  2.10000e+01  1.20000e+02  7.50000e+00  2.86000e-01\n",
            "   8.10000e-01  3.89407e+02  2.34600e+01  7.78400e+02  1.35000e+00\n",
            "   2.75000e+00  1.47200e+01  1.67700e+01  8.28000e+00  8.00000e+00\n",
            "  -2.18400e+02 -1.17800e+02 -5.82000e+01 -1.04000e+02 -1.16900e+02\n",
            "  -5.30000e+01  6.92000e+01  1.85000e+01 -9.85000e+01 -1.18100e+02\n",
            "  -1.23000e+02]\n",
            " [ 1.00000e+00  1.85000e+01  1.35000e+02  7.20000e+00  2.68000e-01\n",
            "   7.50000e-01  3.60685e+02  9.90000e+00  5.54064e+02  6.00000e-01\n",
            "   3.11000e+00  1.53200e+01  1.32700e+01  1.65600e+01  8.00000e+00\n",
            "  -6.84000e+01 -4.28000e+01  1.68000e+01 -2.90000e+01 -4.19000e+01\n",
            "   2.20000e+01  1.44200e+02  9.35000e+01 -2.35000e+01 -4.31000e+01\n",
            "  -4.80000e+01]\n",
            " [ 2.00000e+00  2.00000e+01  1.60000e+02  7.40000e+00  1.99000e-01\n",
            "   8.55000e-01  4.10949e+02  5.54000e+00  1.65536e+02  6.00000e-01\n",
            "   5.00000e+00  2.44900e+01  2.63900e+01  6.21000e+00  8.00000e+00\n",
            "  -4.34000e+01 -3.03000e+01  2.93000e+01 -1.65000e+01 -2.94000e+01\n",
            "   3.45000e+01  1.56700e+02  1.06000e+02 -1.10000e+01 -3.06000e+01\n",
            "  -3.55000e+01]\n",
            " [ 3.00000e+00  2.75000e+01  1.20000e+02  6.90000e+00  2.20000e-01\n",
            "   7.50000e-01  3.60685e+02  2.69300e+01  3.23008e+02  1.40000e-01\n",
            "   1.66000e+00  1.03100e+01  9.41000e+00  1.44900e+01  8.00000e+00\n",
            "  -2.08400e+02 -1.12800e+02 -5.32000e+01 -9.90000e+01 -1.11900e+02\n",
            "  -4.80000e+01  7.42000e+01  2.35000e+01 -9.35000e+01 -1.13100e+02\n",
            "  -1.18000e+02]\n",
            " [ 4.00000e+00  2.10000e+01  1.20000e+02  7.50000e+00  2.86000e-01\n",
            "   8.10000e-01  3.89407e+02  2.34600e+01  7.78400e+02  1.35000e+00\n",
            "   2.75000e+00  1.47200e+01  1.67700e+01  8.28000e+00  8.00000e+00\n",
            "  -2.37200e+02 -1.23200e+02 -9.78000e+01 -8.63000e+01 -8.55000e+01\n",
            "  -2.90000e+00  1.06500e+02  1.62000e+02 -2.33000e+01 -1.14600e+02\n",
            "  -1.25000e+02]\n",
            " [ 5.00000e+00  2.50000e+01  1.20000e+02  7.10000e+00  1.78000e-01\n",
            "   3.80000e-01  1.83566e+02  3.09000e+01  2.91200e+02  1.80000e-01\n",
            "   1.58000e+00  1.44900e+01  1.40500e+01  1.65600e+01  8.00000e+00\n",
            "  -3.37200e+02 -1.73200e+02 -1.47800e+02 -1.36300e+02 -1.35500e+02\n",
            "  -5.29000e+01  5.65000e+01  1.12000e+02 -7.33000e+01 -1.64600e+02\n",
            "  -1.75000e+02]\n",
            " [ 6.00000e+00  3.00000e+01  9.50000e+01  7.60000e+00  1.74000e-01\n",
            "   3.60000e-01  1.73992e+02  4.95000e+01  3.02960e+02  3.60000e-01\n",
            "   1.59000e+00  1.05800e+01  8.13000e+00  1.17300e+01  8.00000e+00\n",
            "  -3.87200e+02 -1.98200e+02 -1.72800e+02 -1.61300e+02 -1.60500e+02\n",
            "  -7.79000e+01  3.15000e+01  8.70000e+01 -9.83000e+01 -1.89600e+02\n",
            "  -2.00000e+02]\n",
            " [ 7.00000e+00  2.50000e+01  1.30000e+02  7.90000e+00  1.58000e-01\n",
            "   3.90000e-01  1.88353e+02  1.11000e+01  3.32304e+02  9.00000e-02\n",
            "   2.71000e+00  7.51000e+00  9.43000e+00  1.17300e+01  8.00000e+00\n",
            "  -3.87200e+02 -1.98200e+02 -1.72800e+02 -1.61300e+02 -1.60500e+02\n",
            "  -7.79000e+01  3.15000e+01  8.70000e+01 -9.83000e+01 -1.89600e+02\n",
            "  -2.00000e+02]\n",
            " [ 8.00000e+00  2.10000e+01  1.20000e+02  7.50000e+00  2.86000e-01\n",
            "   8.10000e-01  3.89407e+02  2.34600e+01  7.78400e+02  1.35000e+00\n",
            "   2.75000e+00  1.47200e+01  1.67700e+01  8.28000e+00  6.00000e+00\n",
            "  -2.32300e+02 -9.37000e+01 -5.65000e+01 -9.52000e+01 -1.08300e+02\n",
            "  -7.67000e+01  5.20000e+00 -3.64000e+01 -5.58000e+01 -1.16000e+02\n",
            "  -1.24200e+02]\n",
            " [ 9.00000e+00  1.85000e+01  1.35000e+02  7.20000e+00  2.68000e-01\n",
            "   7.50000e-01  3.60685e+02  9.90000e+00  5.54064e+02  6.00000e-01\n",
            "   3.11000e+00  1.53200e+01  1.32700e+01  1.65600e+01  6.00000e+00\n",
            "  -8.23000e+01 -1.87000e+01  1.85000e+01 -2.02000e+01 -3.33000e+01\n",
            "  -1.70000e+00  8.02000e+01  3.86000e+01  1.92000e+01 -4.10000e+01\n",
            "  -4.92000e+01]\n",
            " [ 1.00000e+01  2.35000e+01  1.40000e+02  7.10000e+00  2.26000e-01\n",
            "   6.60000e-01  3.17602e+02  1.46500e+01  3.34096e+02  7.10000e-01\n",
            "   2.57000e+00  1.66200e+01  1.91800e+01  1.72500e+01  6.00000e+00\n",
            "  -6.23000e+01 -8.70000e+00  2.85000e+01 -1.02000e+01 -2.33000e+01\n",
            "   8.30000e+00  9.02000e+01  4.86000e+01  2.92000e+01 -3.10000e+01\n",
            "  -3.92000e+01]\n",
            " [ 1.10000e+01  2.75000e+01  1.20000e+02  6.90000e+00  2.20000e-01\n",
            "   7.50000e-01  3.60685e+02  2.69300e+01  3.23008e+02  1.40000e-01\n",
            "   1.66000e+00  1.03100e+01  9.41000e+00  1.44900e+01  6.00000e+00\n",
            "  -2.22300e+02 -8.87000e+01 -5.15000e+01 -9.02000e+01 -1.03300e+02\n",
            "  -7.17000e+01  1.02000e+01 -3.14000e+01 -5.08000e+01 -1.11000e+02\n",
            "  -1.19200e+02]\n",
            " [ 1.20000e+01  1.85000e+01  1.35000e+02  7.20000e+00  2.68000e-01\n",
            "   7.50000e-01  3.60685e+02  9.90000e+00  5.54064e+02  6.00000e-01\n",
            "   3.11000e+00  1.53200e+01  1.32700e+01  1.65600e+01  5.00000e+00\n",
            "  -9.86000e+01 -4.92000e+01 -8.80000e+00 -4.04000e+01 -2.56000e+01\n",
            "   1.27000e+02  6.17000e+01  1.72000e+01  9.66000e+01 -1.70000e+00\n",
            "  -3.38000e+01]\n",
            " [ 1.30000e+01  2.10000e+01  9.50000e+01  7.50000e+00  1.38000e-01\n",
            "   3.30000e-01  1.59631e+02  6.73000e+00  2.14928e+02  2.80000e-01\n",
            "   1.76000e+00  1.27000e+01  1.08500e+01  1.31100e+01  7.00000e+00\n",
            "  -1.78600e+02 -8.92000e+01 -4.88000e+01 -8.04000e+01 -6.56000e+01\n",
            "   8.70000e+01  2.17000e+01 -2.28000e+01  5.66000e+01 -4.17000e+01\n",
            "  -7.38000e+01]\n",
            " [ 1.40000e+01  2.35000e+01  8.00000e+01  7.60000e+00  1.52000e-01\n",
            "   4.80000e-01  2.31436e+02  9.50000e+00  4.07344e+02  3.20000e-01\n",
            "   1.41000e+00  1.79100e+01  8.98000e+00  2.00100e+01  5.00000e+00\n",
            "  -8.36000e+01 -4.17000e+01 -1.30000e+00 -3.29000e+01 -1.81000e+01\n",
            "   1.34500e+02  6.92000e+01  2.47000e+01  1.04100e+02  5.80000e+00\n",
            "  -2.63000e+01]\n",
            " [ 1.50000e+01  2.00000e+01  1.60000e+02  7.40000e+00  1.99000e-01\n",
            "   8.55000e-01  4.10949e+02  5.54000e+00  1.65536e+02  6.00000e-01\n",
            "   5.00000e+00  2.44900e+01  2.63900e+01  6.21000e+00  5.00000e+00\n",
            "  -7.36000e+01 -3.67000e+01  3.70000e+00 -2.79000e+01 -1.31000e+01\n",
            "   1.39500e+02  7.42000e+01  2.97000e+01  1.09100e+02  1.08000e+01\n",
            "  -2.13000e+01]\n",
            " [ 1.60000e+01  2.25000e+01  1.87000e+02  8.10000e+00  2.10000e-01\n",
            "   4.20000e-01  2.02714e+02  2.89100e+01  4.13280e+02  2.20000e-01\n",
            "   9.00000e-01  4.94000e+00  4.40000e+00  2.13900e+01  5.00000e+00\n",
            "  -1.68600e+02 -8.42000e+01 -4.38000e+01 -7.54000e+01 -6.06000e+01\n",
            "   9.20000e+01  2.67000e+01 -1.78000e+01  6.16000e+01 -3.67000e+01\n",
            "  -6.88000e+01]\n",
            " [ 1.70000e+01  3.00000e+01  9.50000e+01  7.60000e+00  1.74000e-01\n",
            "   3.60000e-01  1.73992e+02  4.95000e+01  3.02960e+02  3.60000e-01\n",
            "   1.59000e+00  1.05800e+01  8.13000e+00  1.17300e+01  7.00000e+00\n",
            "  -3.98600e+02 -1.99200e+02 -1.58800e+02 -1.90400e+02 -1.75600e+02\n",
            "  -2.30000e+01 -8.83000e+01 -1.32800e+02 -5.34000e+01 -1.51700e+02\n",
            "  -1.83800e+02]\n",
            " [ 1.80000e+01  2.10000e+01  9.50000e+01  7.50000e+00  1.38000e-01\n",
            "   3.30000e-01  1.59631e+02  6.73000e+00  2.14928e+02  2.80000e-01\n",
            "   1.76000e+00  1.27000e+01  1.08500e+01  1.31100e+01  7.00000e+00\n",
            "  -1.78300e+02 -8.98000e+01 -6.56000e+01 -9.50000e+00  3.53000e+01\n",
            "   1.28700e+02  2.20000e+01  4.66000e+01  7.45000e+01  1.61000e+01\n",
            "   4.81000e+01]\n",
            " [ 1.90000e+01  2.75000e+01  1.25000e+02  7.30000e+00  1.70000e-01\n",
            "   4.95000e-01  2.38617e+02  1.62300e+01  1.35073e+02  6.00000e-01\n",
            "   1.40000e+00  1.06400e+01  1.09500e+01  1.51800e+01  3.00000e+00\n",
            "  -9.83000e+01 -4.98000e+01 -2.56000e+01  3.05000e+01  7.53000e+01\n",
            "   1.68700e+02  6.20000e+01  8.66000e+01  1.14500e+02  5.61000e+01\n",
            "   8.81000e+01]\n",
            " [ 2.00000e+01  2.25000e+01  1.87000e+02  8.10000e+00  2.10000e-01\n",
            "   4.20000e-01  2.02714e+02  2.89100e+01  4.13280e+02  2.20000e-01\n",
            "   9.00000e-01  4.94000e+00  4.40000e+00  2.13900e+01  3.00000e+00\n",
            "  -1.68300e+02 -8.48000e+01 -6.06000e+01 -4.50000e+00  4.03000e+01\n",
            "   1.33700e+02  2.70000e+01  5.16000e+01  7.95000e+01  2.11000e+01\n",
            "   5.31000e+01]\n",
            " [ 2.10000e+01  2.70000e+01  1.10000e+02  7.30000e+00  1.66000e-01\n",
            "   4.00000e-01  1.93140e+02  2.44000e+01  2.40128e+02  3.00000e-01\n",
            "   2.19000e+00  3.88000e+00  4.74000e+00  1.24200e+01  3.00000e+00\n",
            "  -3.48300e+02 -1.74800e+02 -1.50600e+02 -9.45000e+01 -4.97000e+01\n",
            "   4.37000e+01 -6.30000e+01 -3.84000e+01 -1.05000e+01 -6.89000e+01\n",
            "  -3.69000e+01]\n",
            " [ 2.20000e+01  2.70000e+01  1.10000e+02  8.00000e+00  1.75000e-01\n",
            "   4.35000e-01  2.09894e+02  4.75000e+00  1.38544e+02  2.80000e-01\n",
            "   1.25000e+00  4.40000e+00  4.12000e+00  8.97000e+00  3.00000e+00\n",
            "  -3.48300e+02 -1.74800e+02 -1.50600e+02 -9.45000e+01 -4.97000e+01\n",
            "   4.37000e+01 -6.30000e+01 -3.84000e+01 -1.05000e+01 -6.89000e+01\n",
            "  -3.69000e+01]\n",
            " [ 2.30000e+01  2.75000e+01  1.25000e+02  7.30000e+00  1.70000e-01\n",
            "   4.95000e-01  2.38617e+02  1.62300e+01  1.35073e+02  6.00000e-01\n",
            "   1.40000e+00  1.06400e+01  1.09500e+01  1.51800e+01  4.00000e+00\n",
            "  -9.69000e+01 -4.42000e+01  1.00000e-01  1.64100e+02  1.51800e+02\n",
            "   5.13600e+02  3.56000e+02  2.02200e+02  2.42900e+02  2.58100e+02\n",
            "   1.73600e+02]\n",
            " [ 2.40000e+01  2.70000e+01  1.10000e+02  7.30000e+00  1.66000e-01\n",
            "   4.00000e-01  1.93140e+02  2.44000e+01  2.40128e+02  3.00000e-01\n",
            "   2.19000e+00  3.88000e+00  4.74000e+00  1.24200e+01  4.00000e+00\n",
            "  -3.46900e+02 -1.69200e+02 -1.24900e+02  3.91000e+01  2.68000e+01\n",
            "   3.88600e+02  2.31000e+02  7.72000e+01  1.17900e+02  1.33100e+02\n",
            "   4.86000e+01]\n",
            " [ 2.50000e+01  2.70000e+01  9.50000e+01  7.80000e+00  1.71000e-01\n",
            "   2.70000e-01  1.30909e+02  3.89000e+01  2.88736e+02  1.30000e-01\n",
            "   7.80000e-01  5.62000e+00  3.24000e+00  8.28000e+00  4.00000e+00\n",
            "  -3.96900e+02 -1.94200e+02 -1.49900e+02  1.41000e+01  1.80000e+00\n",
            "   3.63600e+02  2.06000e+02  5.22000e+01  9.29000e+01  1.08100e+02\n",
            "   2.36000e+01]\n",
            " [ 2.60000e+01  2.70000e+01  1.10000e+02  8.00000e+00  1.75000e-01\n",
            "   4.35000e-01  2.09894e+02  4.75000e+00  1.38544e+02  2.80000e-01\n",
            "   1.25000e+00  4.40000e+00  4.12000e+00  8.97000e+00  4.00000e+00\n",
            "  -3.46900e+02 -1.69200e+02 -1.24900e+02  3.91000e+01  2.68000e+01\n",
            "   3.88600e+02  2.31000e+02  7.72000e+01  1.17900e+02  1.33100e+02\n",
            "   4.86000e+01]\n",
            " [ 2.70000e+01  2.60000e+01  1.65000e+02  8.00000e+00  2.50000e-01\n",
            "   3.30000e-01  1.59631e+02  2.49400e+01  2.96240e+02  4.40000e-01\n",
            "   1.47000e+00  7.96000e+00  5.83000e+00  5.52000e+00  4.00000e+00\n",
            "  -4.96900e+02 -2.44200e+02 -1.99900e+02 -3.59000e+01 -4.82000e+01\n",
            "   3.13600e+02  1.56000e+02  2.20000e+00  4.29000e+01  5.81000e+01\n",
            "  -2.64000e+01]\n",
            " [ 2.80000e+01  2.35000e+01  1.40000e+02  7.10000e+00  2.26000e-01\n",
            "   6.60000e-01  3.17602e+02  1.46500e+01  3.34096e+02  7.10000e-01\n",
            "   2.57000e+00  1.66200e+01  1.91800e+01  1.72500e+01  2.00000e+00\n",
            "  -7.82000e+01 -4.00000e+01 -3.39000e+01 -3.45000e+01 -3.91000e+01\n",
            "   8.07000e+01  3.14700e+02 -2.60000e+00  5.34000e+01 -3.78000e+01\n",
            "  -3.97000e+01]\n",
            " [ 2.90000e+01  2.50000e+01  1.00000e+02  7.00000e+00  9.00000e-02\n",
            "   4.50000e-01  2.17075e+02  7.12000e+00  5.62240e+02  5.70000e-01\n",
            "   2.59000e+00  1.83800e+01  1.24400e+01  5.52000e+00  2.00000e+00\n",
            "  -1.25200e+02 -6.35000e+01 -5.74000e+01 -5.80000e+01 -6.26000e+01\n",
            "   5.72000e+01  2.91200e+02 -2.61000e+01  2.99000e+01 -6.13000e+01\n",
            "  -6.32000e+01]\n",
            " [ 3.00000e+01  2.25000e+01  1.87000e+02  8.10000e+00  2.10000e-01\n",
            "   4.20000e-01  2.02714e+02  2.89100e+01  4.13280e+02  2.20000e-01\n",
            "   9.00000e-01  4.94000e+00  4.40000e+00  2.13900e+01  2.00000e+00\n",
            "  -1.68200e+02 -8.50000e+01 -7.89000e+01 -7.95000e+01 -8.41000e+01\n",
            "   3.57000e+01  2.69700e+02 -4.76000e+01  8.40000e+00 -8.28000e+01\n",
            "  -8.47000e+01]\n",
            " [ 3.10000e+01  2.50000e+01  1.20000e+02  7.10000e+00  1.78000e-01\n",
            "   3.80000e-01  1.83566e+02  3.09000e+01  2.91200e+02  1.80000e-01\n",
            "   1.58000e+00  1.44900e+01  1.40500e+01  1.65600e+01  1.00000e+00\n",
            "  -3.36600e+02 -1.59500e+02 -1.37500e+02  7.59000e+01  1.57500e+02\n",
            "   3.83500e+02  1.25100e+02  4.15900e+02  1.04900e+02 -1.12400e+02\n",
            "  -1.61000e+02]\n",
            " [ 3.20000e+01  3.00000e+01  9.50000e+01  7.60000e+00  1.74000e-01\n",
            "   3.60000e-01  1.73992e+02  4.95000e+01  3.02960e+02  3.60000e-01\n",
            "   1.59000e+00  1.05800e+01  8.13000e+00  1.17300e+01  1.00000e+00\n",
            "  -3.86600e+02 -1.84500e+02 -1.62500e+02  5.09000e+01  1.32500e+02\n",
            "   3.58500e+02  1.00100e+02  3.90900e+02  7.99000e+01 -1.37400e+02\n",
            "  -1.86000e+02]\n",
            " [ 3.30000e+01  2.50000e+01  1.30000e+02  7.90000e+00  1.58000e-01\n",
            "   3.90000e-01  1.88353e+02  1.11000e+01  3.32304e+02  9.00000e-02\n",
            "   2.71000e+00  7.51000e+00  9.43000e+00  1.17300e+01  1.00000e+00\n",
            "  -3.86600e+02 -1.84500e+02 -1.62500e+02  5.09000e+01  1.32500e+02\n",
            "   3.58500e+02  1.00100e+02  3.90900e+02  7.99000e+01 -1.37400e+02\n",
            "  -1.86000e+02]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv9YrsxFFTfe",
        "colab_type": "code",
        "outputId": "080e3fbf-4b7b-4508-ae69-116cc7469dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        }
      },
      "source": [
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(output_data)\n",
        "print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "print(onehot_encoded)\n",
        "# invert first example\n",
        "inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "print(inverted)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11 16  6 13 11 14  5 15 11 16  9 13 16  7 10  6  3  5  7  8  3  1  2  8\n",
            "  1 12  2  0  9  4  3 14  5 15]\n",
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]]\n",
            "['Rice']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp3WA3QjvhwX",
        "colab_type": "code",
        "outputId": "ea7d44fe-5d02-407c-bf2c-36f39e367378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "xgb_model = XGBRegressor(max_depth=8, \n",
        "                         n_estimators=500, \n",
        "                         min_child_weight=1000,  \n",
        "                         colsample_bytree=0.7, \n",
        "                         subsample=0.7, \n",
        "                         eta=0.3, \n",
        "                         seed=0)\n",
        "xgb_model.fit(input_data, \n",
        "              onehot_encoded , \n",
        "              eval_metric=\"rmse\", \n",
        "              eval_set=[(input_data, onehot_encoded )], \n",
        "              verbose=20, \n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[04:22:35] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
            "[0]\tvalidation_0-rmse:0.466264\n",
            "[20]\tvalidation_0-rmse:0.24338\n",
            "[40]\tvalidation_0-rmse:0.235789\n",
            "[60]\tvalidation_0-rmse:0.235355\n",
            "[80]\tvalidation_0-rmse:0.235307\n",
            "[100]\tvalidation_0-rmse:0.235339\n",
            "[120]\tvalidation_0-rmse:0.235296\n",
            "[140]\tvalidation_0-rmse:0.235324\n",
            "[160]\tvalidation_0-rmse:0.235321\n",
            "[180]\tvalidation_0-rmse:0.235319\n",
            "[200]\tvalidation_0-rmse:0.235385\n",
            "[220]\tvalidation_0-rmse:0.235296\n",
            "[240]\tvalidation_0-rmse:0.235294\n",
            "[260]\tvalidation_0-rmse:0.235294\n",
            "[280]\tvalidation_0-rmse:0.235321\n",
            "[300]\tvalidation_0-rmse:0.235347\n",
            "[320]\tvalidation_0-rmse:0.235302\n",
            "[340]\tvalidation_0-rmse:0.235645\n",
            "[360]\tvalidation_0-rmse:0.235468\n",
            "[380]\tvalidation_0-rmse:0.235642\n",
            "[400]\tvalidation_0-rmse:0.235297\n",
            "[420]\tvalidation_0-rmse:0.235296\n",
            "[440]\tvalidation_0-rmse:0.2353\n",
            "[460]\tvalidation_0-rmse:0.235296\n",
            "[480]\tvalidation_0-rmse:0.235379\n",
            "[499]\tvalidation_0-rmse:0.235393\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "             colsample_bynode=1, colsample_bytree=0.7, eta=0.3, gamma=0,\n",
              "             importance_type='gain', learning_rate=0.1, max_delta_step=0,\n",
              "             max_depth=8, min_child_weight=1000, missing=None, n_estimators=500,\n",
              "             n_jobs=1, nthread=None, objective='reg:linear', random_state=0,\n",
              "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=0, silent=None,\n",
              "             subsample=0.7, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4L9lpF4aSxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = xgb_model.predict(input_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8QFhDM-WEP_",
        "colab_type": "code",
        "outputId": "2b67e4ae-86f6-4a34-a70c-b114f7d088aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "rf_model = RandomForestRegressor(n_estimators=50, max_depth=7, random_state=0, n_jobs=-1)\n",
        "rf_model.fit(input_data,onehot_encoded)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=7,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=50, n_jobs=-1,\n",
              "                      oob_score=False, random_state=0, verbose=0,\n",
              "                      warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kne-kY_tX3Qr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "38492991-78a4-45a7-e959-822387db5418"
      },
      "source": [
        "rf_train_pred = rf_model.predict(input_data)\n",
        "print(rf_train_pred)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.00222222 0.01613636 0.01617605 0.         0.00894444 0.0065\n",
            "  0.01535714 0.0126912  0.00555556 0.0564531  0.01270707 0.77966017\n",
            "  0.00615079 0.0353824  0.01463492 0.00777778 0.00365079]\n",
            " [0.00768926 0.02114164 0.01510073 0.00911783 0.01507937 0.005\n",
            "  0.01123016 0.01150794 0.01292735 0.05025946 0.0190293  0.00730159\n",
            "  0.0180464  0.01507937 0.03623016 0.01480159 0.73045788]\n",
            " [0.00978716 0.04114502 0.04170924 0.00767677 0.01893001 0.01203247\n",
            "  0.46175108 0.04893939 0.02481169 0.08518398 0.01645382 0.03202381\n",
            "  0.01046898 0.01642857 0.08251804 0.02256061 0.06757937]\n",
            " [0.01717532 0.03275613 0.02814574 0.01121573 0.0399531  0.00793651\n",
            "  0.01768398 0.02410534 0.02968254 0.04379509 0.02275613 0.01982684\n",
            "  0.02812771 0.50948773 0.10106421 0.04505772 0.02123016]\n",
            " [0.00222222 0.01977273 0.01799423 0.         0.00894444 0.0065\n",
            "  0.01535714 0.01632756 0.00919192 0.0564531  0.01452525 0.74147835\n",
            "  0.00615079 0.0153824  0.05463492 0.00959596 0.00546898]\n",
            " [0.01786797 0.03121934 0.03561688 0.02151876 0.05173304 0.03407937\n",
            "  0.02449495 0.03959957 0.01795455 0.06588312 0.02037662 0.02160462\n",
            "  0.02752525 0.0238925  0.46262915 0.09079004 0.01321429]\n",
            " [0.00871573 0.0125404  0.01049351 0.00181818 0.02085065 0.72829365\n",
            "  0.01307143 0.05915873 0.01838961 0.0085     0.00581818 0.0065\n",
            "  0.00757937 0.01365079 0.05276263 0.02935714 0.0025    ]\n",
            " [0.02185065 0.02937734 0.02998846 0.02477994 0.02816883 0.07493651\n",
            "  0.02159957 0.0529329  0.02802597 0.01518398 0.02144661 0.01222222\n",
            "  0.03689033 0.07077201 0.06002525 0.45922006 0.01257937]\n",
            " [0.00222222 0.01613636 0.01617605 0.         0.00894444 0.0065\n",
            "  0.01535714 0.0126912  0.00555556 0.0564531  0.01270707 0.77966017\n",
            "  0.00615079 0.0353824  0.01463492 0.00777778 0.00365079]\n",
            " [0.00768926 0.02561133 0.02025225 0.00911783 0.01007937 0.005\n",
            "  0.01789683 0.0126443  0.01656371 0.0535928  0.01834749 0.00911977\n",
            "  0.0155464  0.01257937 0.01956349 0.01661977 0.72977606]\n",
            " [0.00842158 0.04352547 0.0397306  0.00621379 0.01943651 0.01681818\n",
            "  0.03401804 0.01700144 0.02917483 0.562056   0.02959496 0.01827128\n",
            "  0.02017483 0.04367027 0.06833622 0.02282035 0.02073565]\n",
            " [0.01717532 0.03675613 0.03214574 0.01121573 0.0239531  0.01393651\n",
            "  0.02368398 0.06410534 0.02968254 0.04779509 0.02275613 0.01982684\n",
            "  0.02812771 0.51348773 0.06106421 0.03305772 0.02123016]\n",
            " [0.00768926 0.02811133 0.02025225 0.00911783 0.01507937 0.005\n",
            "  0.01789683 0.0151443  0.01656371 0.0335928  0.02084749 0.00911977\n",
            "  0.0180464  0.01507937 0.01956349 0.01661977 0.73227606]\n",
            " [0.01802453 0.04972078 0.04556133 0.02134343 0.03980375 0.01957937\n",
            "  0.03835354 0.47549856 0.02686869 0.02665224 0.02192352 0.01925613\n",
            "  0.03457215 0.02266017 0.06843723 0.05734704 0.01439755]\n",
            " [0.02719286 0.07201537 0.06249756 0.09708103 0.04166234 0.01267532\n",
            "  0.04770346 0.0601811  0.04261422 0.12769886 0.17450261 0.02056566\n",
            "  0.04438983 0.02131313 0.03618615 0.07087302 0.04084749]\n",
            " [0.01178716 0.05259957 0.04952742 0.00967677 0.0267482  0.01803247\n",
            "  0.46975108 0.05457576 0.02681169 0.04918398 0.02027201 0.03202381\n",
            "  0.01428716 0.02042857 0.04251804 0.03419697 0.06757937]\n",
            " [0.01879459 0.02099156 0.02679409 0.73708103 0.01439899 0.\n",
            "  0.01149495 0.02578788 0.01899301 0.00775225 0.02137202 0.00666667\n",
            "  0.028221   0.0025     0.01835859 0.03013709 0.01065629]\n",
            " [0.00507937 0.01072222 0.01107937 0.         0.01921429 0.77029365\n",
            "  0.01707143 0.05915873 0.01657143 0.01694444 0.00622222 0.01094444\n",
            "  0.00757937 0.01787302 0.01316667 0.01335714 0.00472222]\n",
            " [0.01802453 0.04972078 0.04556133 0.02134343 0.03780375 0.01557937\n",
            "  0.03835354 0.47549856 0.04686869 0.02265224 0.01992352 0.01525613\n",
            "  0.03457215 0.02266017 0.06443723 0.05734704 0.01439755]\n",
            " [0.02537468 0.06684005 0.07836264 0.02220008 0.06110678 0.01171429\n",
            "  0.04947258 0.04057792 0.42657454 0.03291242 0.02885903 0.01656566\n",
            "  0.02991292 0.0302417  0.02382756 0.03968903 0.01576812]\n",
            " [0.01879459 0.02099156 0.02679409 0.71708103 0.01439899 0.\n",
            "  0.01149495 0.02578788 0.03899301 0.00775225 0.02137202 0.00666667\n",
            "  0.028221   0.0025     0.01835859 0.03013709 0.01065629]\n",
            " [0.04542158 0.35008608 0.06359135 0.0218249  0.04140765 0.01972222\n",
            "  0.03856494 0.11309957 0.0474223  0.03637202 0.0435091  0.02573232\n",
            "  0.03364308 0.02553535 0.03145382 0.03926623 0.02334749]\n",
            " [0.03779532 0.11600672 0.34188645 0.0219223  0.03121789 0.01085714\n",
            "  0.06499639 0.12645887 0.04011422 0.03241242 0.02991459 0.02434343\n",
            "  0.024278   0.02475758 0.01938312 0.04010967 0.0135459 ]\n",
            " [0.01427128 0.04483838 0.06125108 0.01070707 0.03011328 0.01171429\n",
            "  0.01877128 0.02412987 0.55606638 0.02334199 0.03689899 0.00989899\n",
            "  0.0402381  0.02478716 0.05542929 0.02627994 0.01126263]\n",
            " [0.02723976 0.3287376  0.06635326 0.0218249  0.03440765 0.0175404\n",
            "  0.04790693 0.07202814 0.1074223  0.04438067 0.04282728 0.02858947\n",
            "  0.03438983 0.0238925  0.04128066 0.0389026  0.02227606]\n",
            " [0.04455578 0.03965318 0.03515052 0.11344467 0.02743795 0.03139755\n",
            "  0.02403391 0.08828066 0.02591941 0.02928472 0.03250838 0.00980159\n",
            "  0.22061999 0.0948355  0.06914502 0.09184632 0.02208486]\n",
            " [0.01597713 0.09534005 0.36283017 0.02010412 0.02921789 0.00685714\n",
            "  0.06888384 0.08606926 0.07647786 0.03678472 0.02991459 0.02720058\n",
            "  0.04570657 0.02561472 0.02375541 0.03429149 0.01497447]\n",
            " [0.27699445 0.04866184 0.05223132 0.01983356 0.05466883 0.05539755\n",
            "  0.02232756 0.03511328 0.03370729 0.04404734 0.02421473 0.00694444\n",
            "  0.06280253 0.01975613 0.04413059 0.08486147 0.11430708]\n",
            " [0.0066034  0.0438285  0.03639727 0.00621379 0.02125469 0.01681818\n",
            "  0.02735137 0.02063781 0.04917483 0.53690448 0.02959496 0.01827128\n",
            "  0.02017483 0.03821573 0.0631847  0.02463853 0.04073565]\n",
            " [0.03512049 0.04537734 0.05694084 0.01912121 0.28246392 0.02521429\n",
            "  0.07199495 0.10501948 0.03304906 0.02315873 0.01838312 0.01761111\n",
            "  0.02647691 0.10229365 0.0466912  0.0599329  0.03115079]\n",
            " [0.01879459 0.02099156 0.02679409 0.73708103 0.01439899 0.\n",
            "  0.01149495 0.02578788 0.01899301 0.00775225 0.02137202 0.00666667\n",
            "  0.028221   0.0025     0.01835859 0.03013709 0.01065629]\n",
            " [0.01643939 0.02128788 0.03197114 0.01684343 0.05127994 0.01789755\n",
            "  0.03163709 0.03169192 0.0740404  0.11207287 0.01399495 0.0224127\n",
            "  0.04466811 0.02197835 0.44829654 0.03011472 0.01337302]\n",
            " [0.01303391 0.02335859 0.01671573 0.00431818 0.02735065 0.69611183\n",
            "  0.02088961 0.04165873 0.03838961 0.01876263 0.00985859 0.01094444\n",
            "  0.01189755 0.01987302 0.01862121 0.02349351 0.00472222]\n",
            " [0.02505772 0.06605411 0.04025108 0.02950216 0.03355772 0.04275469\n",
            "  0.04052886 0.0424026  0.07055123 0.02877994 0.02508297 0.0140404\n",
            "  0.04343074 0.05477201 0.03143939 0.3951746  0.01661977]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYPwVbp5X9rW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45f257ec-2c27-4139-8b81-ec4c24832f49"
      },
      "source": [
        "print('Train rmse:', np.sqrt(mean_squared_error(onehot_encoded, rf_train_pred)))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train rmse: 0.1273710198239808\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee8pZeKSYGoc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}